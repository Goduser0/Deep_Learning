{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import keras\n",
    "import sklearn\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的相对地址\n",
    "dataset_train_dir = './EMNIST_Byclass_Small/emnist_train.pkl'\n",
    "dataset_test_dir = './EMNIST_Byclass_Small/emnist_test.pkl'\n",
    "\n",
    "# 将数据集文件解压缩，读取为字典（按照dataset_description.txt文件所示）\n",
    "dataset_train_dict = pickle.load(file=open(dataset_train_dir, 'rb'))\n",
    "dataset_test_dict = pickle.load(file=open(dataset_test_dir, 'rb'))\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.5\n",
    "\n",
    "class EMNIST(data.Dataset):\n",
    "    def __init__(self,  X, y, transform=None):\n",
    "        self.transform = transform\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        self.XX = self.X[index]\n",
    "        self.yy = self.y[index]\n",
    "        if self.transform:\n",
    "            self.XX = self.transform(self.XX)\n",
    "        return self.XX, self.yy\n",
    "\n",
    "x_train = dataset_train_dict['data'].astype('float32')\n",
    "y_train = dataset_train_dict['labels'].reshape(-1).astype('int64')\n",
    "#y_train = nn.functional.one_hot(torch.from_numpy(y_train))\n",
    "y_train = torch.tensor(y_train).to(torch.int64)\n",
    "# y_train = np.asarray(y_train, dtype=float)\n",
    "\n",
    "x_test = dataset_test_dict['data'].astype('float32')\n",
    "y_test = dataset_test_dict['labels'].reshape(-1).astype('int64')\n",
    "#y_test = nn.functional.one_hot(torch.from_numpy(y_test))\n",
    "y_test = torch.tensor(y_test).to(torch.int64)\n",
    "# y_test = np.asarray(y_test, dtype=float)\n",
    "\n",
    "emnist_train = EMNIST(x_train, y_train, transform=T.Compose([T.ToTensor()]))\n",
    "train_iter = data.DataLoader(emnist_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "emnist_test = EMNIST(x_test, y_test, transform=T.Compose([T.ToTensor()]))\n",
    "test_iter = data.DataLoader(emnist_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(784,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(256,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(256,62)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from d2l import torch as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "class Accumulator(object):\n",
    "    \"\"\"累加器\"\"\"\n",
    "    def __init__(self, n):\n",
    "        # 创建len=n的list\n",
    "        self.data = [0.0]*n\n",
    "        \n",
    "    def add(self, *args):\n",
    "        # data累加args\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        # 重置累加器\n",
    "        self.data = [0.0]*len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"计时器\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times=[]\n",
    "        self.start()\n",
    "        \n",
    "    def start(self):\n",
    "        # 记录开始时间戳\n",
    "        self.tik = time.time()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "    \n",
    "    def avg(self):\n",
    "        return sum(self.times) / len(self.times)\n",
    "    \n",
    "    def sum(self):\n",
    "        return sum(self.times)\n",
    "    \n",
    "    def cumsum(self):\n",
    "        return np.array(self.times).cumsum().tolist()    \n",
    "\n",
    "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
    "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
    "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n",
    "\n",
    "def cal_correct(y_hat, y):\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "\n",
    "    cmp = astype(y_hat, y.dtype) == y\n",
    "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device=None):\n",
    "    \"\"\"计算模型在数据集上的准确率\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    metric = Accumulator(2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(cal_correct(net(X), y), size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "###########################################################################################################\n",
    "# FUNCTION: trainer()\n",
    "###########################################################################################################\n",
    "def trainer(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    \n",
    "    device = torch.device(device)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss_fuction = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    timer = Timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            # y_hat = np.argmax(y_hat.detach().numpy(), axis=1)\n",
    "            loss = loss_fuction(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                metric.add(loss*X.shape[0], cal_correct(y_hat, y),X.shape[0])\n",
    "            timer.stop()\n",
    "            \n",
    "        train_loss = metric[0] / metric[2]\n",
    "        train_acc = metric[1] / metric[2]\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        print(f'epoch{epoch+1}:')\n",
    "        print(f'loss{train_loss:.3f}, train acc{train_acc:.3f}, '\n",
    "            f'test acc {test_acc:.3f}')\n",
    "        print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "            f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch1:\n",
      "loss8.103, train acc0.146, test acc 0.269\n",
      "374045.5 examples/sec on cuda:0\n",
      "epoch2:\n",
      "loss3.187, train acc0.243, test acc 0.329\n",
      "182844.9 examples/sec on cuda:0\n",
      "epoch3:\n",
      "loss2.858, train acc0.300, test acc 0.376\n",
      "119529.9 examples/sec on cuda:0\n",
      "epoch4:\n",
      "loss2.589, train acc0.345, test acc 0.436\n",
      "90546.0 examples/sec on cuda:0\n",
      "epoch5:\n",
      "loss2.389, train acc0.397, test acc 0.482\n",
      "72176.7 examples/sec on cuda:0\n",
      "epoch6:\n",
      "loss2.181, train acc0.435, test acc 0.518\n",
      "59964.6 examples/sec on cuda:0\n",
      "epoch7:\n",
      "loss2.038, train acc0.463, test acc 0.551\n",
      "51425.6 examples/sec on cuda:0\n",
      "epoch8:\n",
      "loss1.928, train acc0.487, test acc 0.579\n",
      "44955.7 examples/sec on cuda:0\n",
      "epoch9:\n",
      "loss1.852, train acc0.504, test acc 0.604\n",
      "40006.3 examples/sec on cuda:0\n",
      "epoch10:\n",
      "loss1.761, train acc0.523, test acc 0.626\n",
      "36788.2 examples/sec on cuda:0\n"
     ]
    }
   ],
   "source": [
    "trainer(net, train_iter, test_iter, num_epochs, 0.0005, torch.device('cuda:0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
